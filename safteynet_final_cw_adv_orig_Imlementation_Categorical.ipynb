{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "safteynet_final_cw_adv_orig_Imlementation_Categorical.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-N_6A-1hAma",
        "outputId": "815b6be7-c33f-40fb-90fe-9dc3bff6c8f1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbMiirQk7Zhc"
      },
      "source": [
        "import tensorflow\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.layers as layers\n",
        "from keras.models import Model\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import scipy.io as sio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZAJSD3fY7zBB"
      },
      "source": [
        "from keras.initializers import glorot_uniform\n",
        "\n",
        "\n",
        "def identity_block(input_tensor, kernel_size, filters, stage, block):\n",
        "    \"\"\" \n",
        "    An identity block.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_tensor:\n",
        "\n",
        "    kernel_size: int\n",
        "        The kernel size of middle conv layer at main path.\n",
        "\n",
        "    filters: list[int]\n",
        "        The filters of 3 conv layer at main path.\n",
        "\n",
        "    stage: int\n",
        "        Current stage label, used for generating layer names.\n",
        "\n",
        "    block: : str\n",
        "        'a','b'..., current block label, used for generating layer names.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Output tensor for the block.\n",
        "    \"\"\"\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # for batch normalization layer, we assume\n",
        "    # the input data is in channel last format\n",
        "    bn_axis = 3\n",
        "\n",
        "    filters1, filters2, filters3 = filters\n",
        "  \n",
        "    # main path, note that setting the kernel_initializer seed here is only used\n",
        "    # for reproducibility, we techniqually don't need it\n",
        "    x = layers.Conv2D(filters1, kernel_size=(1, 1), strides=(1, 1),\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='valid', name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, strides=(1, 1),\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, kernel_size=(1, 1), strides=(1, 1),\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='valid', name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "\n",
        "    # this line is the core component of resnet, the skip connection, i.e.\n",
        "    # having a shortcut to the main path before the activation, when addition\n",
        "    # is performed on convolutional layers, the element-wise addition is performed\n",
        "    # on their feature maps, i.e. channel by channel\n",
        "    x = layers.add([x, input_tensor])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsmpzMv37zDh"
      },
      "source": [
        "def conv_block(input_tensor, kernel_size, filters, stage, block, strides=(2, 2)):\n",
        "    \"\"\" \n",
        "    A block that has a conv layer at shortcut.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    input_tensor:\n",
        "    \n",
        "    kernel_size: int\n",
        "        The kernel size of middle conv layer at main path.\n",
        "\n",
        "    filters: list[int]\n",
        "        The filters of 3 conv layer at main path.\n",
        "\n",
        "    stage: int\n",
        "        Current stage label, used for generating layer names.\n",
        "\n",
        "    block: : str\n",
        "        'a','b'..., current block label, used for generating layer names.\n",
        "        \n",
        "    strides : tuple, default (2, 2)\n",
        "        Strides for the first conv layer in the block.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Output tensor for the block.\n",
        "    \"\"\"\n",
        "    conv_name_base = 'res' + str(stage) + block + '_branch'\n",
        "    bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
        "    \n",
        "    # for batch normalization layer, we assume\n",
        "    # the input data is in channel last format,\n",
        "    # which is the case if we are using the default\n",
        "    # keras' backend tensorflow\n",
        "    bn_axis = 3\n",
        "\n",
        "    filters1, filters2, filters3 = filters\n",
        "  \n",
        "    # main path, note that setting the kernel_initializer set here is only used\n",
        "    # for reproducibility, we techniqually don't need it\n",
        "    x = layers.Conv2D(filters1, kernel_size=(1, 1), strides=strides,\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='valid', name=conv_name_base + '2a')(input_tensor)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2a')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters2, kernel_size, strides=(1, 1),\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='same', name=conv_name_base + '2b')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2b')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "\n",
        "    x = layers.Conv2D(filters3, kernel_size=(1, 1), strides=(1, 1),\n",
        "                      kernel_initializer=glorot_uniform(seed=0),\n",
        "                      padding='valid', name=conv_name_base + '2c')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '2c')(x)\n",
        "    \n",
        "    # we resize the input so its dimension will match the output dimension\n",
        "    # of the main path\n",
        "    shortcut = layers.Conv2D(filters3, kernel_size=(1, 1), strides=strides,\n",
        "                             kernel_initializer=glorot_uniform(seed=0),\n",
        "                             padding='valid', name=conv_name_base + '1')(input_tensor)\n",
        "    shortcut = layers.BatchNormalization(axis=bn_axis, name=bn_name_base + '1')(shortcut) \n",
        "\n",
        "    # this line is the core component of resnet, the skip connection, i.e.\n",
        "    # having a shortcut to the main path before the activation\n",
        "    x = layers.add([x, shortcut])\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg93SVlTfSTb"
      },
      "source": [
        "trainpath=\"/content/gdrive/MyDrive/adv_orig_Dataset/mat_adv_orig_Dataset/mat_orig_cw_adv_Dataset/Training\"\n",
        "testpath=\"/content/gdrive/MyDrive/adv_orig_Dataset/mat_adv_orig_Dataset/mat_orig_cw_adv_Dataset/Testing\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBPSxCqoffrF"
      },
      "source": [
        "class_type= os.listdir(trainpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UV-cJ2lMffuB",
        "outputId": "81f2c8d0-cf7c-410c-8073-da7e4c0529e4"
      },
      "source": [
        "class_type"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['orig', 'adv']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "xdHbnVTBfiVf",
        "outputId": "76c38971-c513-4aaf-e1af-5d6dfdb2f784"
      },
      "source": [
        "def load_dataset(path,class_type):\n",
        "  labels = []\n",
        "  mats = []\n",
        "  for item in class_type:\n",
        "    filenames = os.listdir(path + '/' + item)\n",
        "    for f in filenames:\n",
        "      mat_contents = sio.loadmat(path + '/' + item +'/' + f)\n",
        "      if 'orig' in mat_contents:\n",
        "        img=np.array((mat_contents['orig']*255).astype('uint8'))\n",
        "        labels.append(0)\n",
        "      else:\n",
        "        img=np.array((mat_contents['adv']*255).astype('uint8'))\n",
        "        labels.append(1)\n",
        "      mats.append(np.array(img))  \n",
        "\n",
        "  mats = np.array(mats)\n",
        "  labels = np.array(labels) \n",
        "  labels = labels.reshape(-1, 1) \n",
        "  mats,labels = shuffle(mats, labels, random_state = 23)\n",
        "  return mats,labels     \n",
        "\n",
        "'''\n",
        "  for filename in os.listdir(filepath):\n",
        "    mat_contents = sio.loadmat(filepath+'/'+filename)\n",
        "    if 'orig' in mat_contents:\n",
        "      img=np.array((mat_contents['orig']*255).astype('uint8'))\n",
        "      labels.append(0)\n",
        "    else:\n",
        "      img=np.array((mat_contents['adv']*255).astype('uint8'))\n",
        "      labels.append(1)\n",
        "    images.append(np.array(img/255))\n",
        "  images = np.array(images)\n",
        "  labels=np.array(labels)\n",
        "  images,labels = shuffle(images,labels , random_state=4)\n",
        "  '''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\n  for filename in os.listdir(filepath):\\n    mat_contents = sio.loadmat(filepath+'/'+filename)\\n    if 'orig' in mat_contents:\\n      img=np.array((mat_contents['orig']*255).astype('uint8'))\\n      labels.append(0)\\n    else:\\n      img=np.array((mat_contents['adv']*255).astype('uint8'))\\n      labels.append(1)\\n    images.append(np.array(img/255))\\n  images = np.array(images)\\n  labels=np.array(labels)\\n  images,labels = shuffle(images,labels , random_state=4)\\n  \""
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNFCIj4gfiYO"
      },
      "source": [
        "train_x,train_y=load_dataset(trainpath,class_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs4lLSBofsv8"
      },
      "source": [
        "test_x,test_y=load_dataset(testpath,class_type)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9rCKMYrpQA8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2kgBxjopQDa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4D7_QhUfsyk",
        "outputId": "f86840cd-cb1b-4804-e17e-cee4abd33eec"
      },
      "source": [
        "train_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [1],\n",
              "       [0],\n",
              "       ...,\n",
              "       [1],\n",
              "       [1],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvwJW104puOz",
        "outputId": "9ca778ea-35fa-4218-fafc-ec8b1c0aac73"
      },
      "source": [
        "n_classes = 2\n",
        "img_rows, img_cols, img_channel = 224, 224, 3\n",
        "\n",
        "# mnist is grey-scaled image, thus the last dimension, channel size will be 1\n",
        "train_X = train_x.reshape(train_x.shape[0], img_rows, img_cols, img_channel)\n",
        "test_X  = test_x.reshape(test_x.shape[0], img_rows, img_cols, img_channel)\n",
        "input_shape = img_rows, img_cols, img_channel\n",
        "\n",
        "train_X = train_X.astype('float32')\n",
        "test_X  = test_X.astype('float32')\n",
        "\n",
        "# images takes values between 0 - 255, we can normalize it\n",
        "# by dividing every number by 255\n",
        "train_X /= 255\n",
        "test_X /= 255\n",
        "print('train shape:', train_X.shape)\n",
        "\n",
        "# one-hot encode the class (target) vectors\n",
        "train_Y = np_utils.to_categorical(train_y, n_classes)\n",
        "test_Y  = np_utils.to_categorical(test_y , n_classes)\n",
        "#print('Y_train shape:', Y_test1_adv_orig.shape)\n",
        "\n",
        "#Y_train\n",
        "#Y_train1_adv_orig[0].shape\n",
        "train_Y[0].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train shape: (1379, 224, 224, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPsJVHPG77fp"
      },
      "source": [
        "def ResNet(input_shape, n_classes):\n",
        "    \"\"\"\n",
        "    Definition of ResNet\n",
        "    \n",
        "    References\n",
        "    ----------\n",
        "    https://github.com/keras-team/keras-applications/blob/master/keras_applications/resnet50.py\n",
        "    \"\"\"\n",
        "    img_input = layers.Input(shape=input_shape)\n",
        "    \n",
        "    bn_axis = 3\n",
        "    \n",
        "    x = layers.ZeroPadding2D(padding=(3, 3), name='conv1_pad')(img_input)\n",
        "    x = layers.Conv2D(64, (7, 7),\n",
        "                      strides=(2, 2),\n",
        "                      padding='valid',\n",
        "                      kernel_initializer='he_normal',\n",
        "                      name='conv1')(x)\n",
        "    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    x = layers.ZeroPadding2D(padding=(1, 1), name='pool1_pad')(x)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv_block(x, 3, [64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='b')\n",
        "    x = identity_block(x, 3, [64, 64, 256], stage=2, block='c')\n",
        "\n",
        "    x = conv_block(x, 3, [128, 128, 512], stage=3, block='a')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='b')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='c')\n",
        "    x = identity_block(x, 3, [128, 128, 512], stage=3, block='d')\n",
        "    \n",
        "    # the commented out blocks are what's needed to build out the\n",
        "    # full ResNet50 (a ResNet with 50 layers), we won't be needing\n",
        "    # the complexity here\n",
        "    x = conv_block(x, 3, [256, 256, 1024], stage=4, block='a')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='b')\n",
        "    x = identity_block(x, 3, [256, 256, 1024], stage=4, block='c')\n",
        "    # x = identity_block(x, 3, [256, 256, 1024], stage=4, block='d')\n",
        "    # x = identity_block(x, 3, [256, 256, 1024], stage=4, block='e')\n",
        "    # x = identity_block(x, 3, [256, 256, 1024], stage=4, block='f')\n",
        "\n",
        "    # x = conv_block(x, 3, [512, 512, 2048], stage=5, block='a')\n",
        "    # x = identity_block(x, 3, [512, 512, 2048], stage=5, block='b')\n",
        "    # x = identity_block(x, 3, [512, 512, 2048], stage=5, block='c')\n",
        "    \n",
        "    x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "    #img_output = layers.Dense(n_classes, activation='softmax', name='fc' + str(n_classes))(x)\n",
        "    img_output = layers.Dense(2, kernel_regularizer=tensorflow.keras.regularizers.l2(0.01),activation\n",
        "             ='softmax' , name = 'fc' + str(n_classes))(x); \n",
        "    model = Model(inputs=img_input, outputs=img_output, name='resnet')\n",
        "    return model\n",
        "\n",
        "\n",
        "model = ResNet(input_shape, 2)\n",
        "model.compile(optimizer = 'adam', loss = 'squared_hinge', metrics = ['accuracy'])\n",
        "#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "#model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8flYTSS-CYs",
        "outputId": "7f79a715-9bd7-40e2-a483-73fd29714a60"
      },
      "source": [
        "history = model.fit(train_X, train_Y, batch_size=32, epochs=100, validation_data=(test_X,test_Y))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "44/44 [==============================] - 24s 552ms/step - loss: 1.5011 - accuracy: 0.5054 - val_loss: 1.5284 - val_accuracy: 0.4966\n",
            "Epoch 2/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.4256 - accuracy: 0.4931 - val_loss: 1.5136 - val_accuracy: 0.5017\n",
            "Epoch 3/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.3610 - accuracy: 0.5054 - val_loss: 1.3626 - val_accuracy: 0.4730\n",
            "Epoch 4/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.3686 - accuracy: 0.5033 - val_loss: 1.3633 - val_accuracy: 0.5017\n",
            "Epoch 5/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.4002 - accuracy: 0.5054 - val_loss: 1.3060 - val_accuracy: 0.4916\n",
            "Epoch 6/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.3379 - accuracy: 0.4917 - val_loss: 1.4403 - val_accuracy: 0.5051\n",
            "Epoch 7/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.2985 - accuracy: 0.5040 - val_loss: 1.2998 - val_accuracy: 0.4814\n",
            "Epoch 8/100\n",
            "44/44 [==============================] - 24s 552ms/step - loss: 1.2784 - accuracy: 0.5337 - val_loss: 1.4715 - val_accuracy: 0.4882\n",
            "Epoch 9/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.3104 - accuracy: 0.4873 - val_loss: 1.4445 - val_accuracy: 0.5034\n",
            "Epoch 10/100\n",
            "44/44 [==============================] - 24s 549ms/step - loss: 1.2955 - accuracy: 0.4917 - val_loss: 1.3205 - val_accuracy: 0.5152\n",
            "Epoch 11/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.2993 - accuracy: 0.4830 - val_loss: 1.2789 - val_accuracy: 0.4932\n",
            "Epoch 12/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.3025 - accuracy: 0.4859 - val_loss: 1.2702 - val_accuracy: 0.5017\n",
            "Epoch 13/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.2989 - accuracy: 0.5098 - val_loss: 1.2583 - val_accuracy: 0.5034\n",
            "Epoch 14/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.3061 - accuracy: 0.5018 - val_loss: 1.2999 - val_accuracy: 0.5000\n",
            "Epoch 15/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.2849 - accuracy: 0.5134 - val_loss: 1.3215 - val_accuracy: 0.4983\n",
            "Epoch 16/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.2918 - accuracy: 0.4648 - val_loss: 1.3696 - val_accuracy: 0.4983\n",
            "Epoch 17/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.2859 - accuracy: 0.5004 - val_loss: 1.3156 - val_accuracy: 0.5051\n",
            "Epoch 18/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.2798 - accuracy: 0.5091 - val_loss: 1.2864 - val_accuracy: 0.5000\n",
            "Epoch 19/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.2926 - accuracy: 0.4982 - val_loss: 1.3602 - val_accuracy: 0.5034\n",
            "Epoch 20/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.2689 - accuracy: 0.5069 - val_loss: 1.4224 - val_accuracy: 0.5017\n",
            "Epoch 21/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.2769 - accuracy: 0.5018 - val_loss: 1.4152 - val_accuracy: 0.5135\n",
            "Epoch 22/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.2645 - accuracy: 0.5033 - val_loss: 1.3713 - val_accuracy: 0.5101\n",
            "Epoch 23/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.2750 - accuracy: 0.5192 - val_loss: 1.3663 - val_accuracy: 0.5000\n",
            "Epoch 24/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.2745 - accuracy: 0.5156 - val_loss: 1.3407 - val_accuracy: 0.5034\n",
            "Epoch 25/100\n",
            "44/44 [==============================] - 24s 549ms/step - loss: 1.2768 - accuracy: 0.5076 - val_loss: 1.2702 - val_accuracy: 0.5017\n",
            "Epoch 26/100\n",
            "44/44 [==============================] - 24s 549ms/step - loss: 1.2775 - accuracy: 0.4938 - val_loss: 1.2690 - val_accuracy: 0.4932\n",
            "Epoch 27/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.2663 - accuracy: 0.4656 - val_loss: 1.2528 - val_accuracy: 0.5051\n",
            "Epoch 28/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.2635 - accuracy: 0.5134 - val_loss: 1.2563 - val_accuracy: 0.4730\n",
            "Epoch 29/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.2506 - accuracy: 0.5127 - val_loss: 1.2562 - val_accuracy: 0.5017\n",
            "Epoch 30/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.2738 - accuracy: 0.4793 - val_loss: 1.2638 - val_accuracy: 0.5000\n",
            "Epoch 31/100\n",
            "44/44 [==============================] - 24s 552ms/step - loss: 1.2971 - accuracy: 0.5272 - val_loss: 1.2891 - val_accuracy: 0.5084\n",
            "Epoch 32/100\n",
            "44/44 [==============================] - 24s 551ms/step - loss: 1.3031 - accuracy: 0.5199 - val_loss: 1.5006 - val_accuracy: 0.4983\n",
            "Epoch 33/100\n",
            "44/44 [==============================] - 24s 550ms/step - loss: 1.2762 - accuracy: 0.4967 - val_loss: 1.4614 - val_accuracy: 0.4983\n",
            "Epoch 34/100\n",
            "44/44 [==============================] - 24s 549ms/step - loss: 1.2691 - accuracy: 0.4772 - val_loss: 1.3885 - val_accuracy: 0.4899\n",
            "Epoch 35/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2660 - accuracy: 0.4989 - val_loss: 1.2607 - val_accuracy: 0.5017\n",
            "Epoch 36/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2668 - accuracy: 0.4721 - val_loss: 1.2512 - val_accuracy: 0.5017\n",
            "Epoch 37/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2756 - accuracy: 0.4851 - val_loss: 1.2514 - val_accuracy: 0.4983\n",
            "Epoch 38/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2730 - accuracy: 0.4938 - val_loss: 1.3774 - val_accuracy: 0.4865\n",
            "Epoch 39/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2667 - accuracy: 0.5025 - val_loss: 1.3038 - val_accuracy: 0.4747\n",
            "Epoch 40/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2621 - accuracy: 0.4938 - val_loss: 1.2505 - val_accuracy: 0.5068\n",
            "Epoch 41/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2633 - accuracy: 0.4917 - val_loss: 1.2508 - val_accuracy: 0.4966\n",
            "Epoch 42/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2654 - accuracy: 0.4627 - val_loss: 1.2521 - val_accuracy: 0.4882\n",
            "Epoch 43/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2564 - accuracy: 0.4735 - val_loss: 1.2501 - val_accuracy: 0.5017\n",
            "Epoch 44/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2651 - accuracy: 0.4996 - val_loss: 1.3504 - val_accuracy: 0.5017\n",
            "Epoch 45/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2601 - accuracy: 0.5112 - val_loss: 1.2466 - val_accuracy: 0.5051\n",
            "Epoch 46/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2606 - accuracy: 0.4895 - val_loss: 1.2490 - val_accuracy: 0.5068\n",
            "Epoch 47/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2606 - accuracy: 0.4989 - val_loss: 1.2509 - val_accuracy: 0.4966\n",
            "Epoch 48/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2682 - accuracy: 0.5105 - val_loss: 1.3951 - val_accuracy: 0.4713\n",
            "Epoch 49/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2653 - accuracy: 0.4931 - val_loss: 1.2681 - val_accuracy: 0.5135\n",
            "Epoch 50/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2609 - accuracy: 0.5040 - val_loss: 1.2579 - val_accuracy: 0.5017\n",
            "Epoch 51/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2744 - accuracy: 0.4822 - val_loss: 1.2899 - val_accuracy: 0.4983\n",
            "Epoch 52/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2637 - accuracy: 0.5004 - val_loss: 1.2721 - val_accuracy: 0.4983\n",
            "Epoch 53/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2628 - accuracy: 0.4902 - val_loss: 1.2583 - val_accuracy: 0.4983\n",
            "Epoch 54/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2612 - accuracy: 0.4996 - val_loss: 1.2554 - val_accuracy: 0.4983\n",
            "Epoch 55/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2574 - accuracy: 0.4895 - val_loss: 1.2536 - val_accuracy: 0.4949\n",
            "Epoch 56/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2596 - accuracy: 0.5091 - val_loss: 1.2510 - val_accuracy: 0.4949\n",
            "Epoch 57/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2557 - accuracy: 0.5047 - val_loss: 1.3435 - val_accuracy: 0.5017\n",
            "Epoch 58/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2591 - accuracy: 0.5018 - val_loss: 1.3080 - val_accuracy: 0.5101\n",
            "Epoch 59/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2545 - accuracy: 0.5033 - val_loss: 1.2905 - val_accuracy: 0.4932\n",
            "Epoch 60/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2543 - accuracy: 0.4960 - val_loss: 1.2672 - val_accuracy: 0.4983\n",
            "Epoch 61/100\n",
            "44/44 [==============================] - 24s 545ms/step - loss: 1.2555 - accuracy: 0.4873 - val_loss: 1.2567 - val_accuracy: 0.5000\n",
            "Epoch 62/100\n",
            "44/44 [==============================] - 24s 545ms/step - loss: 1.2514 - accuracy: 0.4953 - val_loss: 1.2575 - val_accuracy: 0.5000\n",
            "Epoch 63/100\n",
            "44/44 [==============================] - 24s 545ms/step - loss: 1.2508 - accuracy: 0.5054 - val_loss: 1.2545 - val_accuracy: 0.4983\n",
            "Epoch 64/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2518 - accuracy: 0.4960 - val_loss: 1.2589 - val_accuracy: 0.4983\n",
            "Epoch 65/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2512 - accuracy: 0.4757 - val_loss: 1.2565 - val_accuracy: 0.4949\n",
            "Epoch 66/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2517 - accuracy: 0.5018 - val_loss: 1.2576 - val_accuracy: 0.4983\n",
            "Epoch 67/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2519 - accuracy: 0.5011 - val_loss: 1.2529 - val_accuracy: 0.5017\n",
            "Epoch 68/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2504 - accuracy: 0.5004 - val_loss: 1.2538 - val_accuracy: 0.5017\n",
            "Epoch 69/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2514 - accuracy: 0.5004 - val_loss: 1.2551 - val_accuracy: 0.5017\n",
            "Epoch 70/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2510 - accuracy: 0.4989 - val_loss: 1.2528 - val_accuracy: 0.4983\n",
            "Epoch 71/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2498 - accuracy: 0.5047 - val_loss: 1.2501 - val_accuracy: 0.5068\n",
            "Epoch 72/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2494 - accuracy: 0.5069 - val_loss: 1.2518 - val_accuracy: 0.5000\n",
            "Epoch 73/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2514 - accuracy: 0.4953 - val_loss: 1.2504 - val_accuracy: 0.4983\n",
            "Epoch 74/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2505 - accuracy: 0.4953 - val_loss: 1.2502 - val_accuracy: 0.4916\n",
            "Epoch 75/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2508 - accuracy: 0.4996 - val_loss: 1.2503 - val_accuracy: 0.4983\n",
            "Epoch 76/100\n",
            "44/44 [==============================] - 24s 549ms/step - loss: 1.2506 - accuracy: 0.5011 - val_loss: 1.2503 - val_accuracy: 0.5051\n",
            "Epoch 77/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2498 - accuracy: 0.5040 - val_loss: 1.2509 - val_accuracy: 0.4747\n",
            "Epoch 78/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2505 - accuracy: 0.5069 - val_loss: 1.2505 - val_accuracy: 0.4831\n",
            "Epoch 79/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2507 - accuracy: 0.5033 - val_loss: 1.2516 - val_accuracy: 0.5017\n",
            "Epoch 80/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2493 - accuracy: 0.5178 - val_loss: 1.2505 - val_accuracy: 0.4916\n",
            "Epoch 81/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2514 - accuracy: 0.5091 - val_loss: 1.2506 - val_accuracy: 0.4730\n",
            "Epoch 82/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2511 - accuracy: 0.5134 - val_loss: 1.2529 - val_accuracy: 0.5017\n",
            "Epoch 83/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2495 - accuracy: 0.5062 - val_loss: 1.2669 - val_accuracy: 0.5169\n",
            "Epoch 84/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2512 - accuracy: 0.4996 - val_loss: 1.2623 - val_accuracy: 0.5101\n",
            "Epoch 85/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2577 - accuracy: 0.5018 - val_loss: 1.2786 - val_accuracy: 0.5017\n",
            "Epoch 86/100\n",
            "44/44 [==============================] - 24s 546ms/step - loss: 1.2521 - accuracy: 0.5047 - val_loss: 1.2693 - val_accuracy: 0.5017\n",
            "Epoch 87/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2501 - accuracy: 0.4931 - val_loss: 1.2523 - val_accuracy: 0.5017\n",
            "Epoch 88/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2498 - accuracy: 0.5091 - val_loss: 1.2540 - val_accuracy: 0.4797\n",
            "Epoch 89/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2588 - accuracy: 0.4931 - val_loss: 1.2520 - val_accuracy: 0.5000\n",
            "Epoch 90/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2505 - accuracy: 0.4851 - val_loss: 1.2511 - val_accuracy: 0.4865\n",
            "Epoch 91/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2508 - accuracy: 0.4967 - val_loss: 1.2508 - val_accuracy: 0.4831\n",
            "Epoch 92/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2493 - accuracy: 0.5134 - val_loss: 1.2881 - val_accuracy: 0.4983\n",
            "Epoch 93/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2498 - accuracy: 0.5040 - val_loss: 1.2547 - val_accuracy: 0.5017\n",
            "Epoch 94/100\n",
            "44/44 [==============================] - 24s 547ms/step - loss: 1.2506 - accuracy: 0.5083 - val_loss: 1.2516 - val_accuracy: 0.4831\n",
            "Epoch 95/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2506 - accuracy: 0.5098 - val_loss: 1.2518 - val_accuracy: 0.4848\n",
            "Epoch 96/100\n",
            "44/44 [==============================] - 24s 549ms/step - loss: 1.2511 - accuracy: 0.4902 - val_loss: 1.2511 - val_accuracy: 0.4899\n",
            "Epoch 97/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2500 - accuracy: 0.5054 - val_loss: 1.2518 - val_accuracy: 0.5017\n",
            "Epoch 98/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2499 - accuracy: 0.4975 - val_loss: 1.2525 - val_accuracy: 0.5017\n",
            "Epoch 99/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2503 - accuracy: 0.4967 - val_loss: 1.2512 - val_accuracy: 0.5017\n",
            "Epoch 100/100\n",
            "44/44 [==============================] - 24s 548ms/step - loss: 1.2493 - accuracy: 0.5221 - val_loss: 1.2513 - val_accuracy: 0.4916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU5ART7s7zNT"
      },
      "source": [
        "loss, accuracy = model.evaluate(test_x, test_y)\n",
        "print('Loss = ' + str(loss))\n",
        "print('Test Accuracy = ' + str(accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}